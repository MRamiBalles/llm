{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§  Cortex-8: Transfer Learning & Adaptation\n",
                "\n",
                "## ðŸ¦Ž La Capacidad de AdaptaciÃ³n\n",
                "La verdadera inteligencia no es solo memorizar Shakespeare; es la capacidad de aprender nuevas habilidades.\n",
                "En este experimento:\n",
                "1.  **El Poeta**: Entrenaremos un modelo experto en Literatura (Shakespeare).\n",
                "2.  **El Choque Cultural**: Le pediremos que resuelva MatemÃ¡ticas (sin haberlas visto nunca).\n",
                "3.  **La AdaptaciÃ³n**: Lo \"re-entrenaremos\" (Fine-Tuning) con un nuevo dataset de LÃ³gica/MatemÃ¡ticas.\n",
                "4.  **El Resultado**: Veremos si un Poeta puede convertirse en MatemÃ¡tico.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & LibrerÃ­as\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import random\n",
                "import requests\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"ðŸš€ Cortex-8 Engine: {device.upper()}\")\n",
                "\n",
                "def set_seed(seed=42):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Arquitectura HÃ­brida (La misma de siempre)\n",
                "class MambaBlock(nn.Module):\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
                "        self.out_proj = nn.Linear(d_model, d_model)\n",
                "        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)\n",
                "    def forward(self, x):\n",
                "        B, L, D = x.shape\n",
                "        x_and_res = self.in_proj(x)\n",
                "        x_val, res = x_and_res.chunk(2, dim=-1)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = self.conv(x_val)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = F.silu(x_val)\n",
                "        return self.out_proj(x_val * F.sigmoid(res))\n",
                "\n",
                "class CortexOrganism(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.embedding = nn.Embedding(256, config['d_model'])\n",
                "        self.layers = nn.ModuleList()\n",
                "        for i in range(config['n_layers']): \n",
                "            if i % 2 == 0: self.layers.append(MambaBlock(config['d_model']))\n",
                "            else: self.layers.append(nn.TransformerEncoderLayer(\n",
                "                d_model=config['d_model'], nhead=config['n_heads'], \n",
                "                dim_feedforward=4*config['d_model'], batch_first=True, dropout=0.1\n",
                "            ))\n",
                "        self.ln_f = nn.LayerNorm(config['d_model'])\n",
                "        self.head = nn.Linear(config['d_model'], 256)\n",
                "\n",
                "    def forward(self, idx, targets=None):\n",
                "        x = self.embedding(idx)\n",
                "        for layer in self.layers: x = layer(x)\n",
                "        x = self.ln_f(x)\n",
                "        logits = self.head(x)\n",
                "        loss = None\n",
                "        if targets is not None:\n",
                "            B, T, C = logits.shape\n",
                "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
                "        return logits, loss\n",
                "\n",
                "def generate(model, prompt, max_len=50):\n",
                "    model.eval()\n",
                "    idx = torch.tensor([ord(c) for c in prompt], dtype=torch.long).unsqueeze(0).to(device)\n",
                "    for _ in range(max_len):\n",
                "        with torch.no_grad():\n",
                "            logits, _ = model(idx)\n",
                "            probs = F.softmax(logits[:, -1, :], dim=-1)\n",
                "            next_token = torch.multinomial(probs, 1)\n",
                "            idx = torch.cat((idx, next_token), dim=1)\n",
                "    return \"\".join([chr(i) for i in idx[0].tolist()])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Fase A: Entrenar al Poeta (Shakespeare)\n",
                "Cargamos el dataset literario y entrenamos al modelo base."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset A: Literatura\n",
                "shakespeare_text = requests.get(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\").text\n",
                "data_A = torch.tensor([ord(c) for c in shakespeare_text], dtype=torch.long)\n",
                "\n",
                "def get_batch_A():\n",
                "    ix = torch.randint(len(data_A) - 64, (32,))\n",
                "    x = torch.stack([data_A[i:i+64] for i in ix]).to(device)\n",
                "    y = torch.stack([data_A[i+1:i+65] for i in ix]).to(device)\n",
                "    return x, y\n",
                "\n",
                "print(\"ðŸŽ­ Entrenando al Poeta...\")\n",
                "config = {'n_layers': 4, 'd_model': 256, 'n_heads': 4}\n",
                "model = CortexOrganism(config).to(device)\n",
                "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
                "\n",
                "losses_A = []\n",
                "for i in range(500): # Entrenamiento medio\n",
                "    xb, yb = get_batch_A()\n",
                "    _, loss = model(xb, yb)\n",
                "    optim.zero_grad()\n",
                "    loss.backward()\n",
                "    optim.step()\n",
                "    losses_A.append(loss.item())\n",
                "    if i % 100 == 0: print(f\"   Iter {i}: Loss {loss.item():.4f}\")\n",
                "\n",
                "print(f\"\\nðŸ“œ El Poeta dice: \\\"{generate(model, 'The king ', 50)}\\\"\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Fase B: El Nuevo Mundo (MatemÃ¡ticas)\n",
                "Generamos un dataset sintÃ©tico de aritmÃ©tica simple. Esto es un lenguaje totalmente distinto al inglÃ©s isabelino."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_math_dataset(size=10000):\n",
                "    text = \"\"\n",
                "    for _ in range(size):\n",
                "        a = random.randint(1, 99)\n",
                "        b = random.randint(1, 99)\n",
                "        op = random.choice(['+', '-', '*'])\n",
                "        if op == '+': res = a + b\n",
                "        elif op == '-': res = a - b\n",
                "        else: res = a * b\n",
                "        text += f\"Q: {a}{op}{b}=? A: {res}\\n\"\n",
                "    return text\n",
                "\n",
                "math_text = generate_math_dataset()\n",
                "print(f\"ðŸ§® Dataset MatemÃ¡tico Generado ({len(math_text)} chars)\")\n",
                "print(\"--- Muestra ---\")\n",
                "print(math_text[:100])\n",
                "\n",
                "data_B = torch.tensor([ord(c) for c in math_text], dtype=torch.long)\n",
                "\n",
                "def get_batch_B():\n",
                "    ix = torch.randint(len(data_B) - 64, (32,))\n",
                "    x = torch.stack([data_B[i:i+64] for i in ix]).to(device)\n",
                "    y = torch.stack([data_B[i+1:i+65] for i in ix]).to(device)\n",
                "    return x, y"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Prueba Zero-Shot (Antes de Re-entrenar)\n",
                "Â¿Puede el Poeta resolver matemÃ¡ticas sin estudiar? (Spoiler: No)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"ðŸ§ª Prueba Zero-Shot (Poeta intentando MatemÃ¡ticas):\")\n",
                "prompt = \"Q: 10+10=? A: \"\n",
                "response = generate(model, prompt, 10)\n",
                "print(f\"   Entrada: '{prompt}'\")\n",
                "print(f\"   Salida:  '{response}' (Probablemente alucinaciÃ³n)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6. Fase C: Fine-Tuning (La AdaptaciÃ³n)\n",
                "Tomamos al Poeta y le damos clases intensivas de matemÃ¡ticas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"ðŸŽ“ Re-entrenando (Fine-Tuning) en MatemÃ¡ticas...\")\n",
                "# Bajamos un poco el Learning Rate para no destruir el cerebro previo demasiado rÃ¡pido\n",
                "optim = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
                "\n",
                "losses_B = []\n",
                "for i in range(300): # Entrenamiento corto de adaptaciÃ³n\n",
                "    xb, yb = get_batch_B()\n",
                "    _, loss = model(xb, yb)\n",
                "    optim.zero_grad()\n",
                "    loss.backward()\n",
                "    optim.step()\n",
                "    losses_B.append(loss.item())\n",
                "    if i % 50 == 0: print(f\"   Iter {i}: Loss {loss.item():.4f}\")\n",
                "\n",
                "print(\"âœ… AdaptaciÃ³n Completada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7. VerificaciÃ³n Final\n",
                "Â¿Puede ahora resolver problemas?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"ðŸ§ª Prueba Final (Poeta convertido en MatemÃ¡tico):\")\n",
                "test_prompts = [\n",
                "    \"Q: 5+5=? A: \",\n",
                "    \"Q: 10-2=? A: \",\n",
                "    \"Q: 2*3=? A: \"\n",
                "]\n",
                "\n",
                "for p in test_prompts:\n",
                "    res = generate(model, p, 5).split('\\n')[0] # Tomamos solo la primera lÃ­nea\n",
                "    print(f\"   {p}{res}\")\n",
                "    \n",
                "# Visualizar el cambio de mentalidad\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.plot(losses_A, label='Fase A: Literatura')\n",
                "plt.plot(range(500, 800), losses_B, label='Fase B: MatemÃ¡ticas')\n",
                "plt.axvline(x=500, color='r', linestyle='--', label='Cambio de Dominio')\n",
                "plt.title(\"EvoluciÃ³n del Aprendizaje: De Poeta a MatemÃ¡tico\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}