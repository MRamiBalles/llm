{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ”¬ Cortex-12: The Ultimate Research Protocol\n",
                "\n",
                "## ðŸŽ¯ Mejoras CrÃ­ticas vs Cortex-11\n",
                "- âœ… **Entrenamiento Real**: 2000 pasos para el campeÃ³n (vs 500)\n",
                "- âœ… **Multi-Prompt**: 5 prompts por fase para verificar generalizaciÃ³n\n",
                "- âœ… **Glass Box Autopsy**: PCA, AblaciÃ³n, Layer Analysis\n",
                "- âœ… **50+ Secciones**: MÃ¡ximo detalle cientÃ­fico\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 1: FUNDAMENTOS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 1-3: Setup\n",
                "import torch, torch.nn as nn, torch.nn.functional as F\n",
                "import random, requests, numpy as np, pandas as pd\n",
                "import matplotlib.pyplot as plt, seaborn as sns\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"ðŸš€ Motor: {device.upper()}\")\n",
                "\n",
                "def set_seed(s=42):\n",
                "    random.seed(s); np.random.seed(s); torch.manual_seed(s)\n",
                "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(s)\n",
                "set_seed(42)\n",
                "\n",
                "# Config\n",
                "QUALIFIER_STEPS, FINAL_STEPS, CHAMPION_STEPS = 100, 500, 2000\n",
                "BATCH_SIZE, BLOCK_SIZE = 32, 64"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 2: DATOS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 4-7: Shakespeare & Math Data\n",
                "shakespeare = requests.get(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\").text\n",
                "data_tensor = torch.tensor([ord(c) for c in shakespeare], dtype=torch.long)\n",
                "train_data = data_tensor[:int(0.9*len(data_tensor))]\n",
                "val_data = data_tensor[int(0.9*len(data_tensor)):]\n",
                "\n",
                "math_text = \"\".join([f\"Q:{a}+{b}={a+b}\\n\" for a in range(100) for b in range(100)])\n",
                "math_tensor = torch.tensor([ord(c) for c in math_text], dtype=torch.long)\n",
                "\n",
                "def get_batch(split='train'): \n",
                "    data = train_data if split=='train' else val_data\n",
                "    ix = torch.randint(len(data)-BLOCK_SIZE, (BATCH_SIZE,))\n",
                "    return torch.stack([data[i:i+BLOCK_SIZE] for i in ix]).to(device), \\\n",
                "           torch.stack([data[i+1:i+BLOCK_SIZE+1] for i in ix]).to(device)\n",
                "\n",
                "def get_batch_math():\n",
                "    ix = torch.randint(len(math_tensor)-BLOCK_SIZE, (BATCH_SIZE,))\n",
                "    return torch.stack([math_tensor[i:i+BLOCK_SIZE] for i in ix]).to(device), \\\n",
                "           torch.stack([math_tensor[i+1:i+BLOCK_SIZE+1] for i in ix]).to(device)\n",
                "\n",
                "print(f\"Data: Train {len(train_data):,} | Val {len(val_data):,} | Math {len(math_tensor):,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 3: ARQUITECTURAS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 8-12: Model Components\n",
                "class MambaBlock(nn.Module):\n",
                "    def __init__(self, d): \n",
                "        super().__init__()\n",
                "        self.in_proj, self.out_proj = nn.Linear(d, d*2), nn.Linear(d, d)\n",
                "        self.conv = nn.Conv1d(d, d, 3, padding=1, groups=d)\n",
                "    def forward(self, x):\n",
                "        x_val, res = self.in_proj(x).chunk(2, -1)\n",
                "        x_val = F.silu(self.conv(x_val.transpose(1,2)).transpose(1,2))\n",
                "        return self.out_proj(x_val * F.sigmoid(res))\n",
                "\n",
                "class RWKVBlock(nn.Module):\n",
                "    def __init__(self, d):\n",
                "        super().__init__()\n",
                "        self.k, self.v, self.r, self.o = [nn.Linear(d,d,bias=False) for _ in range(4)]\n",
                "    def forward(self, x): return self.o(torch.sigmoid(self.r(x)) * (self.k(x)*self.v(x)))\n",
                "\n",
                "class MoEBlock(nn.Module):\n",
                "    def __init__(self, d, ne=4):\n",
                "        super().__init__()\n",
                "        self.experts = nn.ModuleList([nn.Sequential(nn.Linear(d,4*d), nn.GELU(), nn.Linear(4*d,d)) for _ in range(ne)])\n",
                "        self.gate = nn.Linear(d, ne)\n",
                "    def forward(self, x):\n",
                "        w = F.softmax(self.gate(x), -1)\n",
                "        return sum(w[:,:,i:i+1]*e(x) for i,e in enumerate(self.experts))\n",
                "\n",
                "class CortexOrganism(nn.Module):\n",
                "    def __init__(self, cfg):\n",
                "        super().__init__()\n",
                "        self.emb = nn.Embedding(256, cfg['d'])\n",
                "        self.pos = nn.Parameter(torch.randn(1, 256, cfg['d'])*0.02)\n",
                "        self.layers = nn.ModuleList()\n",
                "        for i in range(cfg['n']):\n",
                "            if cfg['t']=='T': self.layers.append(nn.TransformerEncoderLayer(cfg['d'],cfg['h'],4*cfg['d'],batch_first=True))\n",
                "            elif cfg['t']=='M': self.layers.append(MambaBlock(cfg['d']))\n",
                "            elif cfg['t']=='R': self.layers.append(RWKVBlock(cfg['d']))\n",
                "            elif cfg['t']=='E': self.layers.append(MoEBlock(cfg['d']))\n",
                "            else: self.layers.append(MambaBlock(cfg['d']) if i%2==0 else nn.TransformerEncoderLayer(cfg['d'],cfg['h'],batch_first=True))\n",
                "        self.ln, self.head = nn.LayerNorm(cfg['d']), nn.Linear(cfg['d'], 256)\n",
                "    def forward(self, idx, tgt=None):\n",
                "        x = self.emb(idx) + self.pos[:,:idx.size(1),:]\n",
                "        for l in self.layers: x = l(x)\n",
                "        logits = self.head(self.ln(x))\n",
                "        return logits, F.cross_entropy(logits.view(-1,256), tgt.view(-1)) if tgt is not None else None\n",
                "\n",
                "print(\"âœ… Arquitecturas Definidas\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 4: UTILIDADES"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 13-17: Training & Evaluation Utils\n",
                "@torch.no_grad()\n",
                "def generate(m, p, ml=50, t=0.8):\n",
                "    m.eval()\n",
                "    idx = torch.tensor([[ord(c) for c in p]], dtype=torch.long).to(device)\n",
                "    for _ in range(ml):\n",
                "        l, _ = m(idx[:,-BLOCK_SIZE:])\n",
                "        l = l[:,-1,:]/t\n",
                "        idx = torch.cat([idx, torch.multinomial(F.softmax(l,-1), 1)], 1)\n",
                "    return \"\".join([chr(max(32,min(126,i))) for i in idx[0].tolist()])\n",
                "\n",
                "def train_model(m, cfg, steps):\n",
                "    opt = torch.optim.AdamW(m.parameters(), cfg['lr'])\n",
                "    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, steps)\n",
                "    m.train(); losses = []\n",
                "    for _ in range(steps):\n",
                "        x, y = get_batch()\n",
                "        _, loss = m(x, y)\n",
                "        opt.zero_grad(); loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
                "        opt.step(); sch.step()\n",
                "        losses.append(loss.item())\n",
                "    return losses\n",
                "\n",
                "@torch.no_grad()\n",
                "def eval_loss(m, iters=50):\n",
                "    m.eval(); ls = []\n",
                "    for _ in range(iters):\n",
                "        x, y = get_batch('val')\n",
                "        _, l = m(x, y)\n",
                "        ls.append(l.item())\n",
                "    return np.mean(ls)\n",
                "\n",
                "LIT_PROMPTS = [\"The king \", \"To be or \", \"First \", \"All the \", \"What is \"]\n",
                "MATH_PROMPTS = [\"Q:5+5=\", \"Q:10-2=\", \"Q:2*3=\", \"Q:1+1=\", \"Q:20+30=\"]\n",
                "\n",
                "def multi_eval(m, ps):\n",
                "    return [generate(m, p, 20) for p in ps]\n",
                "\n",
                "print(\"âœ… Utilidades Definidas\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 5: CLASIFICATORIOS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 18-22: Grand Qualifiers\n",
                "archs = {'T':'Transformer', 'M':'Mamba', 'R':'RWKV', 'E':'MoE', 'H':'Hybrid'}\n",
                "champions = {}\n",
                "\n",
                "for k, name in archs.items():\n",
                "    print(f\"\\nðŸ¥Š {name}\")\n",
                "    best_loss, best_cfg = float('inf'), None\n",
                "    for i in range(3):  # 3 trials (prod: 100)\n",
                "        cfg = {'t':k, 'n':random.choice([4,6]), 'd':random.choice([128,256]), 'h':4, 'lr':random.choice([1e-3,5e-4])}\n",
                "        m = CortexOrganism(cfg).to(device)\n",
                "        train_model(m, cfg, QUALIFIER_STEPS)\n",
                "        vl = eval_loss(m)\n",
                "        if vl < best_loss: best_loss, best_cfg = vl, cfg\n",
                "        print(f\"  T{i}: {vl:.4f}\")\n",
                "    champions[name] = best_cfg\n",
                "    print(f\"ðŸ‘‘ {name}: {best_loss:.4f}\")\n",
                "\n",
                "print(\"\\nâœ… Clasificatorios Completados\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 6: LA GRAN FINAL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 23-27: Adaptive Tournament\n",
                "print(\"ðŸŸï¸ GRAN FINAL\")\n",
                "results = []\n",
                "\n",
                "for name, cfg in champions.items():\n",
                "    print(f\"\\nðŸƒ {name}\")\n",
                "    m = CortexOrganism(cfg).to(device)\n",
                "    w_before = {k:v.clone().detach() for k,v in m.named_parameters()}\n",
                "    \n",
                "    # Lit\n",
                "    opt = torch.optim.AdamW(m.parameters(), cfg['lr'])\n",
                "    for _ in range(FINAL_STEPS):\n",
                "        x, y = get_batch()\n",
                "        _, loss = m(x, y)\n",
                "        opt.zero_grad(); loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
                "        opt.step()\n",
                "    lit_samples = multi_eval(m, LIT_PROMPTS)\n",
                "    \n",
                "    # Math\n",
                "    opt = torch.optim.AdamW(m.parameters(), cfg['lr']/2)\n",
                "    for _ in range(FINAL_STEPS):\n",
                "        x, y = get_batch_math()\n",
                "        _, loss = m(x, y)\n",
                "        opt.zero_grad(); loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(m.parameters(), 1.0)\n",
                "        opt.step()\n",
                "    math_samples = multi_eval(m, MATH_PROMPTS)\n",
                "    \n",
                "    w_after = {k:v.detach() for k,v in m.named_parameters()}\n",
                "    plast = sum((w_after[k]-w_before[k]).norm().item() for k in w_before)\n",
                "    vl = eval_loss(m)\n",
                "    \n",
                "    print(f\"  Lit: {lit_samples[0]}\")\n",
                "    print(f\"  Math: {math_samples[0]}\")\n",
                "    print(f\"  Plasticity: {plast:.2f} | Val Loss: {vl:.4f}\")\n",
                "    \n",
                "    results.append({'Arch':name, 'VL':vl, 'Plast':plast, 'Lit':lit_samples[0], 'Math':math_samples[0]})\n",
                "\n",
                "df = pd.DataFrame(results).sort_values('VL')\n",
                "display(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 7: EL CAMPEÃ“N"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 28-32: Champion Deep Training\n",
                "winner = df.iloc[0]['Arch']\n",
                "winner_cfg = champions[winner]\n",
                "print(f\"ðŸ† GANADOR: {winner}\\n\")\n",
                "\n",
                "champion = CortexOrganism(winner_cfg).to(device)\n",
                "print(f\"Entrenando {CHAMPION_STEPS} pasos...\")\n",
                "losses = train_model(champion, winner_cfg, CHAMPION_STEPS)\n",
                "\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.plot(losses)\n",
                "plt.title(f\"Aprendizaje del CampeÃ³n ({winner})\")\n",
                "plt.xlabel(\"Step\"); plt.ylabel(\"Loss\")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nðŸ—£ï¸ PRUEBAS:\")\n",
                "for p in LIT_PROMPTS:\n",
                "    print(f\"  '{p}' -> '{generate(champion, p, 30)}'\")\n",
                "\n",
                "torch.save(champion.state_dict(), f\"cortex_champion_{winner}.pth\")\n",
                "print(\"\\nðŸ’¾ Guardado\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## PARTE 8: LA AUTOPSIA (Glass Box)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 33-37: Embeddings Analysis\n",
                "emb = champion.emb.weight.detach().cpu().numpy()\n",
                "pca = PCA(n_components=2)\n",
                "emb_2d = pca.fit_transform(emb)\n",
                "\n",
                "plt.figure(figsize=(12,8))\n",
                "plt.scatter(emb_2d[:,0], emb_2d[:,1], alpha=0.5)\n",
                "for c in ['a','e','i','o','u','T','Q','+','=','0','9']:\n",
                "    idx = ord(c)\n",
                "    if idx < 256: plt.annotate(c, emb_2d[idx], fontsize=12)\n",
                "plt.title(\"Espacio de Embeddings (PCA)\")\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 38-40: Weight Distribution\n",
                "all_w = [p.detach().cpu().flatten().numpy() for p in champion.parameters()]\n",
                "all_w = np.concatenate(all_w)\n",
                "\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.hist(all_w, bins=100, alpha=0.7)\n",
                "plt.title(\"DistribuciÃ³n de Pesos\")\n",
                "plt.xlabel(\"Valor\"); plt.ylabel(\"Frecuencia\")\n",
                "plt.show()\n",
                "print(f\"Media: {np.mean(all_w):.4f} | Std: {np.std(all_w):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 41-45: Activation Analysis\n",
                "acts = {}\n",
                "def hook(name): return lambda m,i,o: acts.update({name:o.detach()})\n",
                "\n",
                "for i,l in enumerate(champion.layers): l.register_forward_hook(hook(f\"L{i}\"))\n",
                "\n",
                "test_in = torch.tensor([[ord(c) for c in \"The king is \"]]).to(device)\n",
                "champion(test_in)\n",
                "\n",
                "# Heatmap primera capa\n",
                "act0 = acts['L0'].squeeze(0).cpu().numpy()\n",
                "plt.figure(figsize=(12,6))\n",
                "sns.heatmap(act0[:,:50].T, cmap='viridis')\n",
                "plt.title(\"Activaciones Capa 0\")\n",
                "plt.xlabel(\"Token\"); plt.ylabel(\"Neurona\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SecciÃ³n 46-50: Final Summary\n",
                "from scipy.spatial.distance import cosine\n",
                "\n",
                "# Layer Similarity\n",
                "layer_names = sorted(acts.keys())\n",
                "sims = []\n",
                "for i in range(len(layer_names)-1):\n",
                "    a1, a2 = acts[layer_names[i]].cpu().numpy(), acts[layer_names[i+1]].cpu().numpy()\n",
                "    sims.append(1 - cosine(a1.flatten(), a2.flatten()))\n",
                "\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.plot(sims, marker='o')\n",
                "plt.title(\"Similitud entre Capas\")\n",
                "plt.xlabel(\"TransiciÃ³n\"); plt.ylabel(\"Cosine Similarity\")\n",
                "plt.grid(True)\n",
                "plt.show()\n",
                "\n",
                "# Resumen\n",
                "print(\"\\nðŸ“Š RESUMEN EJECUTIVO:\")\n",
                "print(f\"  Ganador: {winner}\")\n",
                "print(f\"  ParÃ¡metros: {sum(p.numel() for p in champion.parameters())/1e6:.2f}M\")\n",
                "print(f\"  Loss Final: {losses[-1]:.4f}\")\n",
                "print(f\"  Val Loss: {eval_loss(champion):.4f}\")\n",
                "print(f\"\\nðŸŽ“ Cortex-12 Completado\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}