{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# К Cortex-2: Laboratorio de Evoluci贸n de IA\n",
                "\n",
                "Bienvenido al **Cortex-2 Evolutionary Lab**. Este no es un simple script de entrenamiento; es un entorno de investigaci贸n para **descubrir** la arquitectura de IA perfecta.\n",
                "\n",
                "##  El Objetivo\n",
                "En lugar de asumir que \"Transformers es todo lo que necesitas\", usaremos **Algoritmos Gen茅ticos** para evolucionar una arquitectura h铆brida que combine lo mejor de varios mundos:\n",
                "1.  **Mamba (SSM)**: Memoria infinita y eficiente.\n",
                "2.  **Attention**: Razonamiento complejo inmediato.\n",
                "3.  **MoE (Mixture of Experts)**: Especializaci贸n neuronal.\n",
                "\n",
                "##  Caja Blanca: Visualizaci贸n Total\n",
                "En este notebook podr谩s ver:\n",
                "- **El ADN de la IA**: C贸mo se codifica la arquitectura.\n",
                "- **Evoluci贸n en Tiempo Real**: Gr谩ficos interactivos de la supervivencia del m谩s apto.\n",
                "- **Espacio Latente 3D**: Navega por el \"cerebro\" del modelo para ver c贸mo agrupa conceptos.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 0. Preparaci贸n del Laboratorio\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import random\n",
                "import copy\n",
                "import matplotlib.pyplot as plt\n",
                "import plotly.graph_objects as go\n",
                "import plotly.express as px\n",
                "import pandas as pd\n",
                "from sklearn.decomposition import PCA\n",
                "from IPython.display import clear_output, display, HTML\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\" Sistema Iniciado en: {device.upper()}\")\n",
                "\n",
                "# Semilla para reproducibilidad (opcional, para experimentos cient铆ficos)\n",
                "torch.manual_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## К M贸dulo 1: El Genoma (DNA)\n",
                "\n",
                "**驴Por qu茅 esto?**\n",
                "La mayor铆a de los investigadores eligen hiperpar谩metros (capas, cabezas) \"a ojo\". Nosotros definimos un **Espacio de B煤squeda** y dejamos que la evoluci贸n encuentre la combinaci贸n 贸ptima.\n",
                "\n",
                "**Variantes Interesantes:**\n",
                "- **Gen `backbone_type`**: Puede ser 'transformer' (cl谩sico), 'mamba' (r谩pido) o 'hybrid' (lo mejor de ambos).\n",
                "- **Gen `n_experts`**: Define cu谩nto se especializa el cerebro (MoE)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Genome:\n",
                "    def __init__(self):\n",
                "        # Definimos los genes y sus posibles alelos (valores)\n",
                "        self.genes = {\n",
                "            'n_layers': [2, 4, 6, 8],           # Profundidad\n",
                "            'd_model': [128, 256, 384],         # Capacidad de abstracci贸n\n",
                "            'n_heads': [2, 4, 8],               # Paralelismo de atenci贸n\n",
                "            'backbone': ['transformer', 'hybrid'], # Tipo de cerebro\n",
                "            'moe_experts': [0, 4, 8],           # 0 = Denso, >0 = MoE\n",
                "            'learning_rate': [1e-3, 3e-4, 1e-4] # Velocidad de aprendizaje\n",
                "        }\n",
                "        self.dna = self.random_dna()\n",
                "        self.fitness = 0.0\n",
                "\n",
                "    def random_dna(self):\n",
                "        return {k: random.choice(v) for k, v in self.genes.items()}\n",
                "\n",
                "    def mutate(self):\n",
                "        \"\"\" Cambia un gen aleatoriamente \"\"\"\n",
                "        gene_to_mutate = random.choice(list(self.genes.keys()))\n",
                "        self.dna[gene_to_mutate] = random.choice(self.genes[gene_to_mutate])\n",
                "        return f\"К Mutaci贸n: {gene_to_mutate} -> {self.dna[gene_to_mutate]}\"\n",
                "\n",
                "    def crossover(self, other_genome):\n",
                "        \"\"\" Mezcla genes con otro individuo \"\"\"\n",
                "        child = Genome()\n",
                "        for gene in self.genes:\n",
                "            # 50% de probabilidad de heredar de padre o madre\n",
                "            child.dna[gene] = self.dna[gene] if random.random() > 0.5 else other_genome.dna[gene]\n",
                "        return child\n",
                "\n",
                "# Ejemplo de un individuo\n",
                "adam = Genome()\n",
                "print(\"Primer Individuo (Ad谩n):\", adam.dna)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  M贸dulo 2: El Cerebro (Arquitectura Modular)\n",
                "\n",
                "Aqu铆 construimos el modelo bas谩ndonos en el ADN. \n",
                "\n",
                "**Justificaci贸n T茅cnica:**\n",
                "- **ByteEmbedding**: Usamos bytes (0-255) en lugar de tokens BPE. *Ventaja*: Vocabulario peque帽o, robusto a errores ortogr谩ficos, multiling眉e nativo. *Desventaja*: Secuencias m谩s largas (por eso necesitamos Mamba).\n",
                "- **Mamba Block**: Usamos una implementaci贸n simplificada en PyTorch para portabilidad. En producci贸n usar铆amos kernels CUDA.\n",
                "- **MoE (Mixture of Experts)**: Permite tener muchos par谩metros pero usar pocos por token (Inferencia r谩pida)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Bloques Constructivos ---\n",
                "\n",
                "class MambaBlock(nn.Module):\n",
                "    \"\"\" Bloque de Memoria de Estado (Simplificado) \"\"\"\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
                "        self.out_proj = nn.Linear(d_model, d_model)\n",
                "        # Simulaci贸n de la din谩mica de estado\n",
                "        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # x: (B, L, D)\n",
                "        B, L, D = x.shape\n",
                "        x_and_res = self.in_proj(x)\n",
                "        x_val, res = x_and_res.chunk(2, dim=-1)\n",
                "        \n",
                "        # \"Scan\" simulado con convoluci贸n (en realidad ser铆a recurrente)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = self.conv(x_val)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        \n",
                "        x_val = F.silu(x_val)\n",
                "        return self.out_proj(x_val * F.sigmoid(res))\n",
                "\n",
                "class MoELayer(nn.Module):\n",
                "    \"\"\" Capa de Expertos \"\"\"\n",
                "    def __init__(self, d_model, n_experts, top_k=2):\n",
                "        super().__init__()\n",
                "        self.experts = nn.ModuleList([\n",
                "            nn.Sequential(\n",
                "                nn.Linear(d_model, 4 * d_model), nn.GELU(), \n",
                "                nn.Linear(4 * d_model, d_model), nn.Dropout(0.1)\n",
                "            ) for _ in range(n_experts)\n",
                "        ])\n",
                "        self.gate = nn.Linear(d_model, n_experts)\n",
                "        self.top_k = top_k\n",
                "\n",
                "    def forward(self, x):\n",
                "        # Gating simple\n",
                "        gate_logits = self.gate(x)\n",
                "        weights, indices = torch.topk(gate_logits, self.top_k, dim=-1)\n",
                "        weights = F.softmax(weights, dim=-1)\n",
                "        \n",
                "        out = torch.zeros_like(x)\n",
                "        # Iteramos (lento en Python, r谩pido en CUDA/Triton)\n",
                "        for i, expert in enumerate(self.experts):\n",
                "            mask = (indices == i).any(dim=-1)\n",
                "            if mask.any():\n",
                "                out[mask] += expert(x[mask])\n",
                "        return out\n",
                "\n",
                "class CortexOrganism(nn.Module):\n",
                "    \"\"\" El Organismo que evoluciona \"\"\"\n",
                "    def __init__(self, dna):\n",
                "        super().__init__()\n",
                "        self.dna = dna\n",
                "        self.embedding = nn.Embedding(256, dna['d_model']) # Byte-level\n",
                "        self.layers = nn.ModuleList()\n",
                "        \n",
                "        for i in range(dna['n_layers']):\n",
                "            # L贸gica Gen茅tica: 驴Qu茅 tipo de capa construimos?\n",
                "            if dna['backbone'] == 'mamba':\n",
                "                self.layers.append(MambaBlock(dna['d_model']))\n",
                "            elif dna['backbone'] == 'hybrid' and i % 2 == 0:\n",
                "                self.layers.append(MambaBlock(dna['d_model']))\n",
                "            else:\n",
                "                # Transformer cl谩sico\n",
                "                self.layers.append(nn.TransformerEncoderLayer(\n",
                "                    d_model=dna['d_model'], nhead=dna['n_heads'], \n",
                "                    dim_feedforward=4*dna['d_model'], batch_first=True\n",
                "                ))\n",
                "        \n",
                "        # Capa final: 驴MoE o Densa?\n",
                "        if dna['moe_experts'] > 0:\n",
                "            self.final_layer = MoELayer(dna['d_model'], dna['moe_experts'])\n",
                "        else:\n",
                "            self.final_layer = nn.Linear(dna['d_model'], dna['d_model']) # Identidad/Proyecci贸n\n",
                "            \n",
                "        self.ln_f = nn.LayerNorm(dna['d_model'])\n",
                "        self.head = nn.Linear(dna['d_model'], 256)\n",
                "\n",
                "    def forward(self, idx, targets=None):\n",
                "        x = self.embedding(idx)\n",
                "        for layer in self.layers:\n",
                "            x = layer(x)\n",
                "        \n",
                "        if self.dna['moe_experts'] > 0:\n",
                "            x = self.final_layer(x)\n",
                "            \n",
                "        x = self.ln_f(x)\n",
                "        logits = self.head(x)\n",
                "        \n",
                "        loss = None\n",
                "        if targets is not None:\n",
                "            B, T, C = logits.shape\n",
                "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
                "        return logits, loss"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  M贸dulo 3: El Microscopio (Visualizaci贸n 3D)\n",
                "\n",
                "Para entender la \"Caja Blanca\", necesitamos ver qu茅 est谩 aprendiendo el modelo. Usaremos **PCA** para reducir las dimensiones de los embeddings y **Plotly** para navegar en 3D."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_brain_3d(model):\n",
                "    \"\"\" Visualiza el espacio de conceptos del modelo \"\"\"\n",
                "    # Extraemos los embeddings (conceptos que el modelo entiende)\n",
                "    embeddings = model.embedding.weight.detach().cpu().numpy()\n",
                "    \n",
                "    # Reducimos a 3 dimensiones\n",
                "    pca = PCA(n_components=3)\n",
                "    components = pca.fit_transform(embeddings)\n",
                "    \n",
                "    # Mapeamos bytes a caracteres legibles para la etiqueta\n",
                "    labels = [chr(i) if 32 <= i <= 126 else f\"<{i}>\" for i in range(256)]\n",
                "    \n",
                "    df = pd.DataFrame(components, columns=['x', 'y', 'z'])\n",
                "    df['char'] = labels\n",
                "    \n",
                "    fig = px.scatter_3d(\n",
                "        df, x='x', y='y', z='z', \n",
                "        text='char', \n",
                "        title='Mapa Mental 3D (Embeddings)',\n",
                "        opacity=0.7\n",
                "    )\n",
                "    fig.update_traces(textposition='top center')\n",
                "    fig.update_layout(margin=dict(l=0, r=0, b=0, t=30))\n",
                "    fig.show()\n",
                "\n",
                "print(\"Funci贸n de visualizaci贸n lista. Se llamar谩 durante el entrenamiento.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 锔 M贸dulo 4: El Torneo Evolutivo\n",
                "\n",
                "Aqu铆 ocurre la magia. \n",
                "1.  Generamos una **Poblaci贸n** de modelos aleatorios.\n",
                "2.  Los entrenamos brevemente (Sprint).\n",
                "3.  Los peores mueren. Los mejores se reproducen (Crossover) y mutan.\n",
                "4.  Repetimos."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Datos Dummy para probar el bucle (reemplazar con Scraper real)\n",
                "dummy_data = torch.randint(0, 256, (1000,), dtype=torch.long)\n",
                "def get_batch_dummy():\n",
                "    ix = torch.randint(len(dummy_data) - 32, (16,))\n",
                "    x = torch.stack([dummy_data[i:i+32] for i in ix]).to(device)\n",
                "    y = torch.stack([dummy_data[i+1:i+33] for i in ix]).to(device)\n",
                "    return x, y\n",
                "\n",
                "def evolutionary_loop(generations=3, population_size=4):\n",
                "    population = [Genome() for _ in range(population_size)]\n",
                "    history = []\n",
                "    \n",
                "    print(f\" Iniciando Evoluci贸n: {generations} Generaciones, {population_size} Individuos.\")\n",
                "    \n",
                "    for gen in range(generations):\n",
                "        print(f\"\\n--- Generaci贸n {gen+1} ---\")\n",
                "        \n",
                "        # 1. Evaluar Fitness (Entrenar cada modelo)\n",
                "        for i, genome in enumerate(population):\n",
                "            print(f\"Entrenando Individuo {i}: {genome.dna}\")\n",
                "            model = CortexOrganism(genome.dna).to(device)\n",
                "            optimizer = torch.optim.AdamW(model.parameters(), lr=genome.dna['learning_rate'])\n",
                "            \n",
                "            # Mini-Entrenamiento (Sprint)\n",
                "            losses = []\n",
                "            model.train()\n",
                "            for _ in range(20): # Pocas iteraciones para ser r谩pido\n",
                "                xb, yb = get_batch_dummy()\n",
                "                _, loss = model(xb, yb)\n",
                "                optimizer.zero_grad()\n",
                "                loss.backward()\n",
                "                optimizer.step()\n",
                "                losses.append(loss.item())\n",
                "            \n",
                "            # Fitness = Loss final (menor es mejor)\n",
                "            genome.fitness = sum(losses[-5:]) / 5\n",
                "            print(f\"   -> Fitness (Loss): {genome.fitness:.4f}\")\n",
                "            \n",
                "            # Visualizar el mejor de la generaci贸n\n",
                "            if i == 0 and gen == generations - 1:\n",
                "                visualize_brain_3d(model)\n",
                "\n",
                "        # 2. Selecci贸n Natural (Torneo)\n",
                "        population.sort(key=lambda x: x.fitness) # Ordenar por fitness (menor loss primero)\n",
                "        survivors = population[:population_size//2] # Mueren el 50%\n",
                "        print(f\" Han muerto {population_size - len(survivors)} individuos.\")\n",
                "        \n",
                "        # 3. Reproducci贸n y Mutaci贸n\n",
                "        new_population = survivors[:]\n",
                "        while len(new_population) < population_size:\n",
                "            parent_a = random.choice(survivors)\n",
                "            parent_b = random.choice(survivors)\n",
                "            child = parent_a.crossover(parent_b)\n",
                "            if random.random() < 0.3: # 30% Probabilidad de mutaci贸n\n",
                "                print(f\"   {child.mutate()}\")\n",
                "            new_population.append(child)\n",
                "            \n",
                "        population = new_population\n",
                "        best_dna = survivors[0].dna\n",
                "        history.append({'gen': gen, 'best_loss': survivors[0].fitness, 'dna': str(best_dna)})\n",
                "\n",
                "    # Reporte Final\n",
                "    print(\"\\n Evoluci贸n Completada. El Modelo Perfecto es:\")\n",
                "    print(survivors[0].dna)\n",
                "    \n",
                "    # Gr谩fico de Evoluci贸n\n",
                "    hist_df = pd.DataFrame(history)\n",
                "    fig = px.line(hist_df, x='gen', y='best_loss', title='Evoluci贸n del Fitness (Loss)', markers=True)\n",
                "    fig.show()\n",
                "\n",
                "# 隆Ejecutar el Torneo!\n",
                "evolutionary_loop()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}