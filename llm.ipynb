{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# К Cortex-2: Advanced Evolutionary Research Lab\n",
                "\n",
                "##  Estado del Arte y Justificaci贸n Cient铆fica\n",
                "Este entorno implementa una arquitectura de frontera basada en los siguientes papers disruptivos:\n",
                "\n",
                "1.  **Mamba (SSM)**: *Gu, A., & Dao, T. (2023). \"Mamba: Linear-Time Sequence Modeling with Selective State Spaces\".* [arXiv:2312.00752](https://arxiv.org/abs/2312.00752)\n",
                "    *   *Por qu茅*: Resuelve el cuello de botella cuadr谩tico de los Transformers ($O(N^2)$) permitiendo contextos infinitos con coste lineal ($O(N)$).\n",
                "2.  **Mixture of Experts (MoE)**: *Shazeer et al. (2017). \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\".* [arXiv:1701.06538](https://arxiv.org/abs/1701.06538)\n",
                "    *   *Por qu茅*: Desacopla la capacidad de computaci贸n (FLOPs) de la capacidad de memoria (Par谩metros). Permite modelos gigantes que corren r谩pido.\n",
                "3.  **Byte-Level Modeling**: *Xue et al. (2022). \"ByT5: Towards a Token-Free Future\".* [arXiv:2105.13626](https://arxiv.org/abs/2105.13626)\n",
                "    *   *Por qu茅*: Elimina el sesgo humano del Tokenizer. Hace al modelo robusto a \"ruido\" y multiling眉e por defecto.\n",
                "4.  **Neural Architecture Search (NAS)**: *Real et al. (2019). \"Regularized Evolution for Image Classifier Architecture Search\".* [arXiv:1802.01548](https://arxiv.org/abs/1802.01548)\n",
                "    *   *Por qu茅*: La intuici贸n humana falla en espacios de alta dimensi贸n. La evoluci贸n encuentra 贸ptimos locales que nosotros ignoramos.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 0. Configuraci贸n e Importaciones\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import random\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.graph_objects as go\n",
                "import plotly.express as px\n",
                "import pandas as pd\n",
                "from sklearn.decomposition import PCA\n",
                "from IPython.display import clear_output, display\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\" Cortex-2 Engine Active on: {device.upper()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  Arquitectura Modular (Caja Blanca)\n",
                "Hemos instrumentado el c贸digo para extraer **telemetr铆a interna**. No es solo \"forward pass\", es un esc谩ner cerebral."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Componentes Instrumentados ---\n",
                "\n",
                "class InstrumentedAttention(nn.Module):\n",
                "    \"\"\" Atenci贸n con captura de mapas de calor \"\"\"\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.mha = nn.MultiheadAttention(config['d_model'], config['n_heads'], batch_first=True)\n",
                "        self.last_attn_weights = None\n",
                "        \n",
                "    def forward(self, x):\n",
                "        # Capturamos los pesos de atenci贸n (Average across heads for simplicity in visualization)\n",
                "        out, weights = self.mha(x, x, x, need_weights=True, average_attn_weights=True)\n",
                "        self.last_attn_weights = weights.detach().cpu()\n",
                "        return out\n",
                "\n",
                "class MambaBlock(nn.Module):\n",
                "    \"\"\" Bloque Mamba Simplificado \"\"\"\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
                "        self.out_proj = nn.Linear(d_model, d_model)\n",
                "        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        B, L, D = x.shape\n",
                "        x_and_res = self.in_proj(x)\n",
                "        x_val, res = x_and_res.chunk(2, dim=-1)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = self.conv(x_val)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = F.silu(x_val)\n",
                "        return self.out_proj(x_val * F.sigmoid(res))\n",
                "\n",
                "class MoELayer(nn.Module):\n",
                "    \"\"\" MoE con Telemetr铆a de Routing \"\"\"\n",
                "    def __init__(self, d_model, n_experts, top_k=2):\n",
                "        super().__init__()\n",
                "        self.experts = nn.ModuleList([\n",
                "            nn.Sequential(\n",
                "                nn.Linear(d_model, 4 * d_model), nn.GELU(), \n",
                "                nn.Linear(4 * d_model, d_model), nn.Dropout(0.1)\n",
                "            ) for _ in range(n_experts)\n",
                "        ])\n",
                "        self.gate = nn.Linear(d_model, n_experts)\n",
                "        self.top_k = top_k\n",
                "        self.last_routing_dist = None\n",
                "\n",
                "    def forward(self, x):\n",
                "        gate_logits = self.gate(x)\n",
                "        weights, indices = torch.topk(gate_logits, self.top_k, dim=-1)\n",
                "        weights = F.softmax(weights, dim=-1)\n",
                "        \n",
                "        # Telemetr铆a: 驴Qu茅 expertos se activaron?\n",
                "        self.last_routing_dist = indices.detach().cpu().view(-1).bincount(minlength=len(self.experts))\n",
                "        \n",
                "        out = torch.zeros_like(x)\n",
                "        for i, expert in enumerate(self.experts):\n",
                "            mask = (indices == i).any(dim=-1)\n",
                "            if mask.any():\n",
                "                out[mask] += expert(x[mask])\n",
                "        return out\n",
                "\n",
                "class CortexOrganism(nn.Module):\n",
                "    def __init__(self, dna):\n",
                "        super().__init__()\n",
                "        self.dna = dna\n",
                "        self.embedding = nn.Embedding(256, dna['d_model'])\n",
                "        self.layers = nn.ModuleList()\n",
                "        \n",
                "        for i in range(dna['n_layers']):\n",
                "            if dna['backbone'] == 'mamba':\n",
                "                self.layers.append(MambaBlock(dna['d_model']))\n",
                "            elif dna['backbone'] == 'hybrid' and i % 2 == 0:\n",
                "                self.layers.append(MambaBlock(dna['d_model']))\n",
                "            else:\n",
                "                # Usamos nuestra Atenci贸n Instrumentada\n",
                "                self.layers.append(InstrumentedAttention(dna))\n",
                "        \n",
                "        if dna['moe_experts'] > 0:\n",
                "            self.final_layer = MoELayer(dna['d_model'], dna['moe_experts'])\n",
                "        else:\n",
                "            self.final_layer = nn.Linear(dna['d_model'], dna['d_model'])\n",
                "            \n",
                "        self.ln_f = nn.LayerNorm(dna['d_model'])\n",
                "        self.head = nn.Linear(dna['d_model'], 256)\n",
                "\n",
                "    def forward(self, idx, targets=None):\n",
                "        x = self.embedding(idx)\n",
                "        for layer in self.layers:\n",
                "            x = layer(x)\n",
                "        if self.dna['moe_experts'] > 0:\n",
                "            x = self.final_layer(x)\n",
                "        x = self.ln_f(x)\n",
                "        logits = self.head(x)\n",
                "        \n",
                "        loss = None\n",
                "        if targets is not None:\n",
                "            B, T, C = logits.shape\n",
                "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
                "        return logits, loss"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  Visualizaci贸n Avanzada\n",
                "Aqu铆 definimos las herramientas para inspeccionar el modelo."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_attention(model, input_bytes):\n",
                "    \"\"\" Muestra qu茅 bytes miran a qu茅 bytes \"\"\"\n",
                "    # Buscar la 煤ltima capa de atenci贸n\n",
                "    attn_layer = None\n",
                "    for layer in model.layers:\n",
                "        if isinstance(layer, InstrumentedAttention):\n",
                "            attn_layer = layer\n",
                "            \n",
                "    if attn_layer is None or attn_layer.last_attn_weights is None:\n",
                "        print(\"锔 No hay capas de atenci贸n activas o registradas.\")\n",
                "        return\n",
                "\n",
                "    weights = attn_layer.last_attn_weights[0] # Primer batch\n",
                "    \n",
                "    plt.figure(figsize=(10, 8))\n",
                "    sns.heatmap(weights.numpy(), cmap='viridis')\n",
                "    plt.title(\"Mapa de Calor de Atenci贸n (Razonamiento)\")\n",
                "    plt.xlabel(\"Key Token\")\n",
                "    plt.ylabel(\"Query Token\")\n",
                "    plt.show()\n",
                "\n",
                "def visualize_moe_routing(model):\n",
                "    \"\"\" Muestra la carga de trabajo de cada experto \"\"\"\n",
                "    if not hasattr(model, 'final_layer') or not isinstance(model.final_layer, MoELayer):\n",
                "        return\n",
                "        \n",
                "    dist = model.final_layer.last_routing_dist\n",
                "    if dist is None: return\n",
                "    \n",
                "    plt.figure(figsize=(8, 4))\n",
                "    plt.bar(range(len(dist)), dist.numpy(), color='#818cf8')\n",
                "    plt.title(\"Distribuci贸n de Carga de Expertos (MoE)\")\n",
                "    plt.xlabel(\"ID del Experto\")\n",
                "    plt.ylabel(\"Tokens Procesados\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "##  Futuro y Alternativas\n",
                "\n",
                "**驴Qu茅 falta? 驴D贸nde indagar m谩s?**\n",
                "\n",
                "1.  **RWKV (Receptance Weighted Key Value)**: *Peng et al.*. Una alternativa fascinante que entrena como Transformer (paralelo) pero infiere como RNN (serial). Deber铆amos probar a帽adir bloques RWKV al genoma.\n",
                "2.  **Griffin / Hawk**: *Google DeepMind*. Arquitecturas h铆bridas Recurrentes-Atencionales m谩s recientes que Mamba.\n",
                "3.  **Optimizadores Ex贸ticos**: Estamos usando AdamW. Deber铆amos probar **Sophia** (Second-order Clipped Optimization) o **Muon** (Momentum Orthogonalizer) para convergencia m谩s r谩pida.\n",
                "4.  **Curriculum Learning**: El scraper descarga papers, pero deber铆amos ordenarlos por complejidad (L贸gica -> Ciencia -> Literatura) autom谩ticamente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Genoma y Bucle Evolutivo (Igual que antes, pero usando las nuevas clases) ---\n",
                "class Genome:\n",
                "    def __init__(self):\n",
                "        self.genes = {\n",
                "            'n_layers': [2, 4, 6], \n",
                "            'd_model': [128, 256], \n",
                "            'n_heads': [2, 4], \n",
                "            'backbone': ['transformer', 'hybrid'], \n",
                "            'moe_experts': [0, 4, 8], \n",
                "            'learning_rate': [1e-3, 3e-4]\n",
                "        }\n",
                "        self.dna = {k: random.choice(v) for k, v in self.genes.items()}\n",
                "        self.fitness = 0.0\n",
                "    \n",
                "    def mutate(self):\n",
                "        k = random.choice(list(self.genes.keys()))\n",
                "        self.dna[k] = random.choice(self.genes[k])\n",
                "        return f\"К Mutaci贸n: {k} -> {self.dna[k]}\"\n",
                "        \n",
                "    def crossover(self, other):\n",
                "        child = Genome()\n",
                "        for k in self.genes:\n",
                "            child.dna[k] = self.dna[k] if random.random() > 0.5 else other.dna[k]\n",
                "        return child\n",
                "\n",
                "# Datos Dummy\n",
                "dummy_data = torch.randint(0, 256, (1000,), dtype=torch.long)\n",
                "def get_batch():\n",
                "    ix = torch.randint(len(dummy_data) - 32, (16,))\n",
                "    x = torch.stack([dummy_data[i:i+32] for i in ix]).to(device)\n",
                "    y = torch.stack([dummy_data[i+1:i+33] for i in ix]).to(device)\n",
                "    return x, y\n",
                "\n",
                "def run_evolution(generations=3, pop_size=4):\n",
                "    population = [Genome() for _ in range(pop_size)]\n",
                "    \n",
                "    for gen in range(generations):\n",
                "        print(f\"\\n Generaci贸n {gen+1}\")\n",
                "        for i, genome in enumerate(population):\n",
                "            model = CortexOrganism(genome.dna).to(device)\n",
                "            optim = torch.optim.AdamW(model.parameters(), lr=genome.dna['learning_rate'])\n",
                "            \n",
                "            # Sprint Training\n",
                "            losses = []\n",
                "            for _ in range(10):\n",
                "                xb, yb = get_batch()\n",
                "                _, loss = model(xb, yb)\n",
                "                optim.zero_grad()\n",
                "                loss.backward()\n",
                "                optim.step()\n",
                "                losses.append(loss.item())\n",
                "            \n",
                "            genome.fitness = sum(losses[-3:]) / 3\n",
                "            print(f\"   Individuo {i} ({genome.dna['backbone']}): Loss {genome.fitness:.4f}\")\n",
                "            \n",
                "            # Visualizar al campe贸n de la ronda\n",
                "            if i == 0:\n",
                "                visualize_attention(model, xb)\n",
                "                visualize_moe_routing(model)\n",
                "        \n",
                "        # Selecci贸n\n",
                "        population.sort(key=lambda x: x.fitness)\n",
                "        survivors = population[:pop_size//2]\n",
                "        \n",
                "        # Reproducci贸n\n",
                "        new_pop = survivors[:]\n",
                "        while len(new_pop) < pop_size:\n",
                "            parent = random.choice(survivors)\n",
                "            child = parent.crossover(random.choice(survivors))\n",
                "            if random.random() < 0.4: child.mutate()\n",
                "            new_pop.append(child)\n",
                "        population = new_pop\n",
                "\n",
                "run_evolution()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}