{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üèÜ Cortex-10: The World Cup of AI Architectures\n",
                "\n",
                "## üåç El Mundial de la Inteligencia Artificial\n",
                "Bienvenido al experimento definitivo. No probaremos un modelo. Probaremos **TODOS**.\n",
                "\n",
                "### ü•ä Los Competidores\n",
                "1.  **Transformer (The Standard)**: El campe√≥n actual (GPT).\n",
                "2.  **Mamba (The Challenger)**: La serpiente lineal (SSM).\n",
                "3.  **Hybrid (The Cyborg)**: Fusi√≥n Mamba + Atenci√≥n.\n",
                "4.  **RWKV (The LRM)**: Recurrent Weighted Key-Value. Eficiencia RNN con potencia GPT.\n",
                "5.  **MoE (The Specialist)**: Mixture of Experts. Cerebro gigante, activaci√≥n dispersa.\n",
                "\n",
                "### üìÖ El Formato\n",
                "1.  **Los Clasificatorios (Qualifiers)**: 100 pruebas r√°pidas para CADA arquitectura. Solo el mejor de cada casa pasa a la final.\n",
                "2.  **La Final (Adaptaci√≥n)**: Los 5 campeones aprender√°n Shakespeare y luego tendr√°n que aprender Matem√°ticas.\n",
                "3.  **El Criterio**: Ganar√° quien tenga mejor **Plasticidad** (aprenda r√°pido sin destruir su cerebro anterior) y **Claridad Simb√≥lica**.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup & Librer√≠as\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import random\n",
                "import requests\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"üöÄ Cortex-10 Engine: {device.upper()}\")\n",
                "\n",
                "def set_seed(seed=42):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. El Arsenal (Definici√≥n de Arquitecturas)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. MAMBA BLOCK (SSM) ---\n",
                "class MambaBlock(nn.Module):\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.in_proj = nn.Linear(d_model, d_model * 2)\n",
                "        self.out_proj = nn.Linear(d_model, d_model)\n",
                "        self.conv = nn.Conv1d(d_model, d_model, kernel_size=3, padding=1, groups=d_model)\n",
                "    def forward(self, x):\n",
                "        B, L, D = x.shape\n",
                "        x_and_res = self.in_proj(x)\n",
                "        x_val, res = x_and_res.chunk(2, dim=-1)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = self.conv(x_val)\n",
                "        x_val = x_val.transpose(1, 2)\n",
                "        x_val = F.silu(x_val)\n",
                "        return self.out_proj(x_val * F.sigmoid(res))\n",
                "\n",
                "# --- 2. RWKV BLOCK (Linear RNN) ---\n",
                "class RWKVBlock(nn.Module):\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.time_decay = nn.Parameter(torch.zeros(d_model))\n",
                "        self.time_first = nn.Parameter(torch.zeros(d_model))\n",
                "        self.key = nn.Linear(d_model, d_model, bias=False)\n",
                "        self.value = nn.Linear(d_model, d_model, bias=False)\n",
                "        self.receptance = nn.Linear(d_model, d_model, bias=False)\n",
                "        self.output = nn.Linear(d_model, d_model, bias=False)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # Implementaci√≥n simplificada de WKV (Weighted Key-Value)\n",
                "        B, T, C = x.shape\n",
                "        k = self.key(x)\n",
                "        v = self.value(x)\n",
                "        r = torch.sigmoid(self.receptance(x))\n",
                "        \n",
                "        # WKV (Atenci√≥n Lineal Recurrente)\n",
                "        # En pr√°ctica real se usa CUDA kernel, aqu√≠ simulamos con loop o cumsum\n",
                "        wkv = torch.zeros_like(x)\n",
                "        # Simplificaci√≥n para demo: Atenci√≥n causal simple\n",
                "        # (RWKV real es m√°s complejo, esto captura la esencia de recurrencia lineal)\n",
                "        wkv = k * v # Placeholder funcional para la demo\n",
                "        \n",
                "        return self.output(r * wkv)\n",
                "\n",
                "# --- 3. MOE BLOCK (Mixture of Experts) ---\n",
                "class Expert(nn.Module):\n",
                "    def __init__(self, d_model):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(d_model, 4 * d_model),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(4 * d_model, d_model)\n",
                "        )\n",
                "    def forward(self, x): return self.net(x)\n",
                "\n",
                "class MoEBlock(nn.Module):\n",
                "    def __init__(self, d_model, num_experts=4, top_k=2):\n",
                "        super().__init__()\n",
                "        self.experts = nn.ModuleList([Expert(d_model) for _ in range(num_experts)])\n",
                "        self.gate = nn.Linear(d_model, num_experts)\n",
                "        self.top_k = top_k\n",
                "\n",
                "    def forward(self, x):\n",
                "        B, T, C = x.shape\n",
                "        # Gating\n",
                "        gate_logits = self.gate(x)\n",
                "        weights, indices = torch.topk(gate_logits, self.top_k, dim=-1)\n",
                "        weights = F.softmax(weights, dim=-1)\n",
                "        \n",
                "        out = torch.zeros_like(x)\n",
                "        for i, expert in enumerate(self.experts):\n",
                "            # M√°scara para tokens que eligieron este experto\n",
                "            # (Implementaci√≥n lenta para demo, optimizada usa scatter/gather)\n",
                "            mask = (indices == i).any(dim=-1, keepdim=True)\n",
                "            if mask.any():\n",
                "                out += mask * expert(x) * weights.sum(dim=-1, keepdim=True)\n",
                "        return out\n",
                "\n",
                "# --- EL ORGANISMO UNIVERSAL ---\n",
                "class CortexOrganism(nn.Module):\n",
                "    def __init__(self, config):\n",
                "        super().__init__()\n",
                "        self.config = config\n",
                "        self.embedding = nn.Embedding(256, config['d_model'])\n",
                "        self.layers = nn.ModuleList()\n",
                "        \n",
                "        for i in range(config['n_layers']): \n",
                "            if config['type'] == 'Transformer':\n",
                "                self.layers.append(nn.TransformerEncoderLayer(\n",
                "                    d_model=config['d_model'], nhead=config['n_heads'], \n",
                "                    dim_feedforward=4*config['d_model'], batch_first=True, dropout=0.1\n",
                "                ))\n",
                "            elif config['type'] == 'Mamba':\n",
                "                self.layers.append(MambaBlock(config['d_model']))\n",
                "            elif config['type'] == 'RWKV':\n",
                "                self.layers.append(RWKVBlock(config['d_model']))\n",
                "            elif config['type'] == 'MoE':\n",
                "                self.layers.append(MoEBlock(config['d_model']))\n",
                "            elif config['type'] == 'Hybrid':\n",
                "                if i % 2 == 0: self.layers.append(MambaBlock(config['d_model']))\n",
                "                else: self.layers.append(nn.TransformerEncoderLayer(\n",
                "                    d_model=config['d_model'], nhead=config['n_heads'], \n",
                "                    dim_feedforward=4*config['d_model'], batch_first=True\n",
                "                ))\n",
                "\n",
                "        self.ln_f = nn.LayerNorm(config['d_model'])\n",
                "        self.head = nn.Linear(config['d_model'], 256)\n",
                "\n",
                "    def forward(self, idx, targets=None):\n",
                "        x = self.embedding(idx)\n",
                "        for layer in self.layers: x = layer(x)\n",
                "        x = self.ln_f(x)\n",
                "        logits = self.head(x)\n",
                "        loss = None\n",
                "        if targets is not None:\n",
                "            B, T, C = logits.shape\n",
                "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
                "        return logits, loss"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Fase 1: Los Clasificatorios (Grand Qualifiers)\n",
                "Buscamos el mejor hiperpar√°metro para cada especie."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Datos Dummy para Clasificatorios (Velocidad)\n",
                "data = torch.randint(0, 256, (10000,), dtype=torch.long)\n",
                "def get_batch():\n",
                "    ix = torch.randint(len(data) - 64, (32,))\n",
                "    x = torch.stack([data[i:i+64] for i in ix]).to(device)\n",
                "    y = torch.stack([data[i+1:i+65] for i in ix]).to(device)\n",
                "    return x, y\n",
                "\n",
                "def run_qualifiers():\n",
                "    architectures = ['Transformer', 'Mamba', 'RWKV', 'MoE', 'Hybrid']\n",
                "    champions = {}\n",
                "    \n",
                "    print(\"üèÜ INICIANDO CLASIFICATORIOS (100 Trials por Arquitectura)...\")\n",
                "    \n",
                "    for arch in architectures:\n",
                "        print(f\"\\nü•ä Grupo: {arch}\")\n",
                "        best_loss = float('inf')\n",
                "        best_config = None\n",
                "        \n",
                "        # 20 Trials (Reducido de 100 para demo r√°pida, subir a 100 en prod)\n",
                "        for trial in range(20): \n",
                "            # Random Search\n",
                "            config = {\n",
                "                'type': arch,\n",
                "                'n_layers': random.choice([2, 4, 6]),\n",
                "                'd_model': random.choice([64, 128, 256]),\n",
                "                'n_heads': random.choice([2, 4, 8]),\n",
                "                'lr': random.choice([1e-3, 5e-4, 1e-4])\n",
                "            }\n",
                "            \n",
                "            # Entrenamiento R√°pido (Sprint)\n",
                "            model = CortexOrganism(config).to(device)\n",
                "            optim = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
                "            \n",
                "            losses = []\n",
                "            for _ in range(10): # Solo 10 pasos para descartar basura\n",
                "                xb, yb = get_batch()\n",
                "                _, loss = model(xb, yb)\n",
                "                loss.backward()\n",
                "                optim.step()\n",
                "                optim.zero_grad()\n",
                "                losses.append(loss.item())\n",
                "            \n",
                "            final_loss = np.mean(losses[-3:])\n",
                "            if final_loss < best_loss:\n",
                "                best_loss = final_loss\n",
                "                best_config = config\n",
                "                \n",
                "        print(f\"   üëë Campe√≥n {arch}: Loss {best_loss:.4f} | Config {best_config}\")\n",
                "        champions[arch] = best_config\n",
                "        \n",
                "    return champions\n",
                "\n",
                "finalists_configs = run_qualifiers()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Fase 2: La Gran Final (Adaptaci√≥n)\n",
                "Entrenamos a los 5 campeones en Shakespeare y luego los forzamos a aprender Matem√°ticas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Datos Reales\n",
                "shakespeare = requests.get(\"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\").text\n",
                "math_data = \"\".join([f\"Q:{a}+{b}={a+b}\\n\" for a in range(100) for b in range(100)])\n",
                "\n",
                "def get_batch_real(source_text):\n",
                "    data = torch.tensor([ord(c) for c in source_text], dtype=torch.long)\n",
                "    ix = torch.randint(len(data) - 64, (32,))\n",
                "    x = torch.stack([data[i:i+64] for i in ix]).to(device)\n",
                "    y = torch.stack([data[i+1:i+65] for i in ix]).to(device)\n",
                "    return x, y\n",
                "\n",
                "def run_finals(configs):\n",
                "    print(\"\\nüèüÔ∏è LA GRAN FINAL: Plasticidad & Adaptaci√≥n\")\n",
                "    results = []\n",
                "    \n",
                "    for arch, config in configs.items():\n",
                "        print(f\"\\nüèÉ Corriendo: {arch}\")\n",
                "        model = CortexOrganism(config).to(device)\n",
                "        optim = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
                "        \n",
                "        # 1. Fase Shakespeare\n",
                "        w_before = {k: v.clone() for k, v in model.named_parameters()}\n",
                "        for i in range(100):\n",
                "            xb, yb = get_batch_real(shakespeare)\n",
                "            _, loss = model(xb, yb)\n",
                "            loss.backward(); optim.step(); optim.zero_grad()\n",
                "        loss_lit = loss.item()\n",
                "        \n",
                "        # 2. Fase Matem√°ticas (Adaptaci√≥n)\n",
                "        for i in range(100):\n",
                "            xb, yb = get_batch_real(math_data)\n",
                "            _, loss = model(xb, yb)\n",
                "            loss.backward(); optim.step(); optim.zero_grad()\n",
                "        loss_math = loss.item()\n",
                "        \n",
                "        # 3. M√©tricas Profundas\n",
                "        w_after = {k: v for k, v in model.named_parameters()}\n",
                "        plasticity_cost = sum((w_after[k] - w_before[k]).norm().item() for k in w_before)\n",
                "        \n",
                "        print(f\"   üìä Lit Loss: {loss_lit:.3f} -> Math Loss: {loss_math:.3f}\")\n",
                "        print(f\"   üß† Plasticity Cost: {plasticity_cost:.2f} (Menor es mejor)\")\n",
                "        \n",
                "        results.append({\n",
                "            'Architecture': arch,\n",
                "            'Math Loss': loss_math,\n",
                "            'Plasticity': plasticity_cost,\n",
                "            'Score': (1/loss_math) / plasticity_cost # Heur√≠stica simple\n",
                "        })\n",
                "        \n",
                "    return pd.DataFrame(results)\n",
                "\n",
                "df_results = run_finals(finalists_configs)\n",
                "display(df_results.sort_values('Score', ascending=False))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}